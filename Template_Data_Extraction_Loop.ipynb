{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30ac053f-92c7-488f-aaec-a5382c90d2e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop the table\n",
    "spark.sql(\"DROP TABLE schemaPlaceholder.tableName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6df04d03-925b-4544-8ad3-ee25e2b2f7cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Not using f-string over here because I need to define and assign the extract_date inside the loop\n",
    "QUERY = '''\n",
    "\n",
    "SELECT * FROM TableName\n",
    "WHERE date = '{extract_date}'\n",
    "\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fa89f48-3810-4e14-ae85-76eda1f730d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "# Define the start date and end date\n",
    "start_date = date(2024, 2, 2)  # Replace with your desired start date\n",
    "# end_date = date.today()\n",
    "end_date = date(2024, 6, 1)\n",
    "\n",
    "# # Define the specific date value\n",
    "# extract_date = '2024-05-24'\n",
    "\n",
    "# Loop over the dates\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "  # Convert the current_date to string format\n",
    "  extract_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "  # Run query\n",
    "  spark_df =  spark.sql(QUERY.format(extract_date=extract_date)) # Using format to assing the extract_date\n",
    "\n",
    "  # Create the table in the specified schema\n",
    "  spark_df.write.saveAsTable('schemaPlaceholder.tableName', format=\"delta\", mode=\"append\")\n",
    "\n",
    "  # Increment the current_date by one day\n",
    "  current_date += timedelta(days=1)\n",
    "\n",
    "# df3.printSchema()\n",
    "# df3.show()\n",
    "print(\"All done!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Template_Data_Extraction_Loop",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}